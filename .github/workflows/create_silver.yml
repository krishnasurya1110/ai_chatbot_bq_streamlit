name: Deploy to GCS & Create Dataproc Cluster

on:
    push:
        paths:
            - 'silver_layer/dataproc_init.sh'              

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      BUCKET_NAME: dataproc-cluster-spark-jars
      INIT_SCRIPT_LOCAL: dataproc_init.sh
      INIT_SCRIPT_GCS: dataproc_init.sh
      CLUSTER_NAME: rakshaka

    steps:
      - name: Code Checkout
        uses: actions/checkout@v2

      - name: Create JSON credentials file
        id: create-json-credentials
        uses: jsdaniell/create-json@v1.2.3
        with:
          name: "gcloud-service-key.json"
          json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}

      - name: Install the gcloud CLI
        uses: google-github-actions/setup-gcloud@v1
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          export_default_credentials: true

      - name: Authenticate gcloud CLI explicitly
        run: |
          gcloud auth activate-service-account --key-file=gcloud-service-key.json
          gcloud config set project ${{ secrets.GCP_PROJECT_ID }}

      - name: Create GCS bucket if not exists
        run: |
          if ! gsutil ls -b gs://${BUCKET_NAME} >/dev/null 2>&1; then
            echo "Creating GCS bucket: ${BUCKET_NAME}"
            gsutil mb -l us-central1 gs://${BUCKET_NAME}
          else
            echo "GCS bucket ${BUCKET_NAME} already exists."
          fi

      - name: Upload files to GCS
        run: |
          echo "Upload silver layer files to GCS bucket ${BUCKET_NAME}"
          gsutil -m rsync -r silver_layer/ gs://${BUCKET_NAME}

      - name: Create Dataproc Cluster
        run: |
          if ! gcloud dataproc clusters describe ${CLUSTER_NAME} --region=us-central1 > /dev/null 2>&1; then
            echo "Creating Dataproc Cluster: ${CLUSTER_NAME}"
            gcloud dataproc clusters create ${CLUSTER_NAME} \
              --region=us-central1 \
              --zone=us-central1-a \
              --master-machine-type=e2-standard-2 \
              --master-boot-disk-size=50GB \
              --num-workers=3 \
              --worker-machine-type=e2-standard-2 \
              --worker-boot-disk-size=50GB \
              --image-version=2.1-debian11 \
              --initialization-actions=gs://${BUCKET_NAME}/${INIT_SCRIPT_GCS} \
              --optional-components=JUPYTER \
              --enable-component-gateway
          else
            echo "Dataproc Cluster ${CLUSTER_NAME} already exists."
          fi

